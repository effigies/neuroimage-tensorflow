{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Nibable\n",
    "    - In Jupyter homescreen, click New->Terminal \n",
    "    - run `pip install nibabel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "import os, sys, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(x):\n",
    "\tprint x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for genTFrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def select_hipp(x):\n",
    "\tx[x != 17] = 0\n",
    "\tx[x == 17] = 1\n",
    "\treturn x\n",
    "\n",
    "def crop_brain(x):\n",
    "\tx = x[90:130,90:130,90:130] #should take volume zoomed in on hippocampus area\n",
    "\treturn x\n",
    "\n",
    "def preproc_brain(x):\n",
    "\tx = select_hipp(x)\n",
    "\tx = crop_brain(x)   \n",
    "\treturn x\n",
    "\n",
    "def listfiles(folder):\n",
    "\tfor root, folders, files in os.walk(folder):\n",
    "\t\tfor filename in folders + files:\n",
    "\t\t\tyield os.path.join(root, filename)\n",
    "\n",
    "def gen_filename_pairs(data_dir, v_re, l_re):\n",
    "\tunfiltered_filelist=list(listfiles(data_dir))\n",
    "\tinput_list = [item for item in unfiltered_filelist if re.search(v_re,item)]\n",
    "\tlabel_list = [item for item in unfiltered_filelist if re.search(l_re,item)]\n",
    "\tprint(\"input_list size:    \", len(input_list))\n",
    "\tprint(\"label_list size:    \", len(label_list))\n",
    "\tif len(input_list) != len(label_list):\n",
    "\t\tprint(\"input_list size and label_list size don't match\")\n",
    "\t\traise Exception\n",
    "\treturn zip(input_list, label_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a vol/label training set list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input_list size:    ', 2)\n",
      "('label_list size:    ', 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('/notebooks/data/bucker40/train/004/norm.nii.gz',\n",
       "  '/notebooks/data/bucker40/train/004/aseg.nii.gz'),\n",
       " ('/notebooks/data/bucker40/train/008/norm.nii.gz',\n",
       "  '/notebooks/data/bucker40/train/008/aseg.nii.gz')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_pairs = gen_filename_pairs('/notebooks/data/bucker40/train', 'norm', 'aseg')\n",
    "filename_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for writing .tfrecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "\treturn tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "\treturn tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the file `b40train.tfrecord` \n",
    "\n",
    "I guess the biggest lesson learned is tfrecords are a waste of time.  As your data set grows (as it should if you're using neural-nets) they become unweidy.  They can't encode the properties of the data (like input dimensions) and we were getting errors when training before we cropped the data.  You need to write a decoder for your data with tfrecords anyway.  So you might as just feed directly and skip all this encoding nonesense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:\n",
      "('  volume: ', '/notebooks/data/bucker40/train/004/norm.nii.gz')\n",
      "('  label:  ', '/notebooks/data/bucker40/train/004/aseg.nii.gz')\n",
      "DIMS: 404040\n",
      "Processing:\n",
      "('  volume: ', '/notebooks/data/bucker40/train/008/norm.nii.gz')\n",
      "('  label:  ', '/notebooks/data/bucker40/train/008/aseg.nii.gz')\n",
      "DIMS: 404040\n"
     ]
    }
   ],
   "source": [
    "outfile = '/notebooks/data/b40train.tfrecord'\n",
    "writer = tf.python_io.TFRecordWriter(outfile)\n",
    "for v_filename, l_filename in filename_pairs:\n",
    "\n",
    "\tprint(\"Processing:\")\n",
    "\tprint(\"  volume: \", v_filename)\n",
    "\tprint(\"  label:  \", l_filename)\t\n",
    "\n",
    "\t# The volume, in nifti format\t\n",
    "\tv_nii = nib.load(v_filename)\n",
    "\t# The volume, in numpy format\n",
    "\tv_np = v_nii.get_data().astype('int16')\n",
    "\t# The volume, in raw string format\n",
    "\tv_np = crop_brain(v_np)\n",
    "\t# The volume, in raw string format\n",
    "\tv_raw = v_np.tostring()\n",
    "\n",
    "\t# The label, in nifti format\n",
    "\tl_nii = nib.load(l_filename)\n",
    "\t# The label, in numpy format\n",
    "\tl_np = l_nii.get_data().astype('int16')\n",
    "\t# Preprocess the volume\n",
    "\tl_np = preproc_brain(l_np)\n",
    "\t# The label, in raw string format\n",
    "\tl_raw = l_np.tostring()\n",
    "\n",
    "\t# Dimensions\n",
    "\tx_dim = v_np.shape[0]\n",
    "\ty_dim = v_np.shape[1]\n",
    "\tz_dim = v_np.shape[2]\n",
    "\tprint(\"DIMS: \" + str(x_dim) + str(y_dim) + str(z_dim))\n",
    "\n",
    "\t# Put in the original images into array for future check for correctness\n",
    "\t# Uncomment to test (this is a memory hog)\n",
    "\t########################################\n",
    "\t# original_images.append((v_np, l_np))\n",
    "\n",
    "\tdata_point = tf.train.Example(features=tf.train.Features(feature={\n",
    "\t\t'image_raw': _bytes_feature(v_raw),\n",
    "\t\t'label_raw': _bytes_feature(l_raw)}))\n",
    "    \n",
    "\twriter.write(data_point.SerializeToString())\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigate through your jupyter filetree.\n",
    "There should be a data/b40train.tfrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some model and training constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIR='/notebooks/data'\n",
    "CHECKPOINT_DIR='/notebooks/data'\n",
    "TRAIN_FILE='b40-train.tfrecords'\n",
    "VALIDATION_FILE=''\n",
    "IMG_DIM=40\n",
    "NUM_CLASSES=2\n",
    "BATCH_SIZE=2\n",
    "NUM_EPOCHS=2\n",
    "DECAY_STEPS=1.0\n",
    "DECAY_RATE=1.0\n",
    "LEARNING_RATE=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull a record out of tfrecord\n",
    "\n",
    "For 3D convolution, Tensorflow expects tensors in the shape\n",
    "```\n",
    "[Batch, X, Y, Z, Channel]\n",
    "```\n",
    "Here we return a single image/label tensor pair in the shape\n",
    "  - `[X, Y, Z, Channel]` for the image\n",
    "  - `[X, Y, Z]` for the label\n",
    "  \n",
    "Image is returned as float32 (conv3d will complain if it's an int)\n",
    "\n",
    "Here's a  good place to zero-center your data and do other nice things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_decode(filename_queue):\n",
    "\treader = tf.TFRecordReader()\n",
    "\t_, serialized_example = reader.read(filename_queue)\n",
    "\tfeatures = tf.parse_single_example(serialized_example,features={\n",
    "\t\t'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "\t\t'label_raw': tf.FixedLenFeature([], tf.string)})\n",
    "\timage  = tf.cast(tf.decode_raw(features['image_raw'], tf.int16), tf.float32)\n",
    "\tlabels = tf.decode_raw(features['label_raw'], tf.int16)\n",
    "\t\n",
    "\t#PW 2017/03/03: Zero-center data here?\n",
    "\timage.set_shape([IMG_DIM*IMG_DIM*IMG_DIM])\n",
    "\timage  = tf.reshape(image, [IMG_DIM,IMG_DIM,IMG_DIM,1])\n",
    "\t\n",
    "\tlabels.set_shape([IMG_DIM*IMG_DIM*IMG_DIM])\n",
    "\tlabels  = tf.reshape(image, [IMG_DIM,IMG_DIM,IMG_DIM])\n",
    "\t\n",
    "\t# Dimensions (X, Y, Z, channles)\n",
    "\treturn image, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a training batch\n",
    "\t\"\"\"\n",
    "\t\tReads input data num_epochs times.\n",
    "\t\tArgs:\n",
    "\t\t\ttrain: Selects between the training (True) and validation (False) data.\n",
    "\t\t\tbatch_size: Number of examples per returned batch.\n",
    "\t\t\tnum_epochs: Number of times to read the input data, or 0/None to train forever.\n",
    "\t\tReturns:\n",
    "\t\t\tA tuple (images, labels), where:\n",
    "\t\t\t\t* images is a float tensor with shape [batch_size, DIM, DIM, DIM, 1]\n",
    "\t\t\t\t* labels is an int32 tensor with shape [batch_size, DIM, DIM, DIM] with the true label\n",
    "\t\t\tNote that an tf.train.QueueRunner is added to the graph, which\n",
    "\t\t\tmust be run using e.g. tf.train.start_queue_runners().\n",
    "\t\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputs(train, batch_size, num_epochs, filename):\n",
    "\n",
    "\tif not num_epochs: num_epochs = None\n",
    "\t\n",
    "\twith tf.name_scope('input'): \n",
    "\t\tfilename_queue = tf.train.string_input_producer([filename], num_epochs=num_epochs)\n",
    "\t\n",
    "\t# Even when reading in multiple threads, share the filename queue.\n",
    "\timage, label = read_and_decode(filename_queue)\n",
    "\t\n",
    "\t# Shuffle the examples and collect them into batch_size batches.\n",
    "\t# (Internally uses a RandomShuffleQueue.)\n",
    "\t# We run this in two threads to avoid being a bottleneck.\n",
    "\timages, sparse_labels = tf.train.shuffle_batch([image, label], batch_size=batch_size, num_threads=2,capacity=1000 + 3 * batch_size,min_after_dequeue=1000)\n",
    "\t\n",
    "\t# Dimensions (batchsize, X, Y, Z, channles)\n",
    "\treturn images, sparse_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The actual Neural Netowrk Inference Model\n",
    "\n",
    "3D operations used (everything else is the same as 2D heart-labeling example)\n",
    "\n",
    " - Convolution layer (https://www.tensorflow.org/api_docs/python/tf/nn/conv3d)\n",
    "   - `tf.nn.conv3d(input, filter, strides, padding, name=None)`\n",
    "     - input shape: `[batch, depth, height, width, in_channels]`\n",
    "     - filter shape: `[filter_depth, filter_height, filter_width, in_channels, out_channels]`\n",
    "     - strides shape `[1, ?, ?, ?, 1]` (first/last dim must be 1)\n",
    " - Pool layer (https://www.tensorflow.org/api_docs/python/tf/nn/max_pool3d)\n",
    "   - `tf.nn.max_pool3d(input, ksize, strides, padding, name=None)`\n",
    "     - input shape: `[batch, depth, height, width, channels]`\n",
    "     - ksize: The size of the window for each dimension of the input tensor. \n",
    "       - Must have ksize[0] = ksize[4] = 1\n",
    "       - strides shape [1, ?, ?, ?, 1]\n",
    " - Deconvolution layer https://www.tensorflow.org/api_docs/python/tf/nn/conv3d_transpose\n",
    "\t- `tf.nn.conv3d_transpose(value, filter, output_shape, strides, padding='SAME', name=None)`\n",
    "         - value: A 5-D Tensor of type float and shape `[batch, depth, height, width, in_channels]`\n",
    "         - filter: A 5-D Tensor with the same type as value and shape `[depth, height, width, output_channels, in_channels]`. \n",
    "           - filter's in_channels dimension must match that of value.\n",
    "         - output_shape: A 1-D Tensor representing the output shape of the deconvolution op.\n",
    "         - strides: A list of ints. The stride of the sliding window for each dimension of the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images):\t    \n",
    "\tprint_tensor_shape( images, 'images shape inference' )\n",
    "\twith tf.name_scope('Conv1'):\n",
    "\t\tW_conv1 = tf.Variable(tf.truncated_normal([3,3,3,1,10],stddev=0.1,dtype=tf.float32),name='W_conv1')\n",
    "\t\tprint_tensor_shape( W_conv1, 'W_conv1 shape')\n",
    "\t\tconv1_op = tf.nn.conv3d(images, W_conv1, strides=[1,2,2,2,1], padding=\"SAME\", name='conv1_op' )\n",
    "\t\tprint_tensor_shape( conv1_op, 'conv1_op shape')\n",
    "\t\trelu1_op = tf.nn.relu( conv1_op, name='relu1_op' )\n",
    "\t\tprint_tensor_shape( relu1_op, 'relu1_op shape')\n",
    "\twith tf.name_scope('Pool1'):\n",
    "\t\tpool1_op = tf.nn.max_pool3d(relu1_op, ksize=[1,3,3,3,1],strides=[1,2,2,2,1], padding='SAME') \n",
    "\t\tprint_tensor_shape( pool1_op, 'pool1_op shape')\n",
    "\twith tf.name_scope('Conv2'):\n",
    "\t\tW_conv2 = tf.Variable(tf.truncated_normal([3,3,3,10,100],stddev=0.1,dtype=tf.float32),name='W_conv2')\n",
    "\t\tprint_tensor_shape( W_conv2, 'W_conv2 shape')\n",
    "\t\tconv2_op = tf.nn.conv3d( pool1_op, W_conv2, strides=[1,2,2,2,1],padding=\"SAME\", name='conv2_op' )\n",
    "\t\tprint_tensor_shape( conv2_op, 'conv2_op shape')\n",
    "\t\trelu2_op = tf.nn.relu( conv2_op, name='relu2_op' )\n",
    "\t\tprint_tensor_shape( relu2_op, 'relu2_op shape')\n",
    "\twith tf.name_scope('Pool2'):\n",
    "\t\tpool2_op = tf.nn.max_pool3d(relu2_op, ksize=[1,3,3,3,1],strides=[1,2,2,2,1], padding='SAME')\n",
    "\t\tprint_tensor_shape( pool2_op, 'pool2_op shape')\n",
    "\twith tf.name_scope('Conv3'):\n",
    "\t\tW_conv3 = tf.Variable(tf.truncated_normal([3,3,3,100,200],stddev=0.1,dtype=tf.float32),name='W_conv3') \n",
    "\t\tprint_tensor_shape( W_conv3, 'W_conv3 shape')\n",
    "\t\tconv3_op = tf.nn.conv3d( pool2_op, W_conv3, strides=[1,2,2,2,1],padding='SAME', name='conv3_op' )\n",
    "\t\tprint_tensor_shape( conv3_op, 'conv3_op shape')\n",
    "\t\trelu3_op = tf.nn.relu( conv3_op, name='relu3_op' )\n",
    "\t\tprint_tensor_shape( relu3_op, 'relu3_op shape')\n",
    "\twith tf.name_scope('Conv4'):\n",
    "\t\tW_conv4 = tf.Variable(tf.truncated_normal([3,3,3,200,200],stddev=0.1,dtype=tf.float32), name='W_conv4')\n",
    "\t\tprint_tensor_shape( W_conv4, 'W_conv4 shape')\n",
    "\t\tconv4_op = tf.nn.conv3d( relu3_op, W_conv4, strides=[1,2,2,2,1],padding='SAME', name='conv4_op' )\n",
    "\t\tprint_tensor_shape( conv4_op, 'conv4_op shape')\n",
    "\t\trelu4_op = tf.nn.relu( conv4_op, name='relu4_op' )\n",
    "\t\tprint_tensor_shape( relu4_op, 'relu4_op shape')\n",
    "\t\t# optional dropout node.  when set to 1.0 nothing is dropped out\n",
    "\t\tdrop_op = tf.nn.dropout( relu4_op, 1.0 )\n",
    "\t\tprint_tensor_shape( drop_op, 'drop_op shape' )\n",
    "\t# Conv layer to generate the 2 score classes\n",
    "\twith tf.name_scope('Score_classes'):\n",
    "\t\tW_score_classes = tf.Variable(tf.truncated_normal([1,1,1,200,2],stddev=0.1,dtype=tf.float32),name='W_score_classes')\n",
    "\t\tprint_tensor_shape( W_score_classes, 'W_score_classes_shape')\n",
    "\t\tscore_classes_conv_op = tf.nn.conv3d( drop_op, W_score_classes,strides=[1,1,1,1,1], padding='SAME', name='score_classes_conv_op')\n",
    "\t\tprint_tensor_shape( score_classes_conv_op,'score_conv_op shape')\n",
    "\t# Upscore the results to 1x256x256x256x2 image\n",
    "\twith tf.name_scope('Upscore'):\n",
    "\t\tW_upscore = tf.Variable(tf.truncated_normal([31,31,31,2,2],stddev=0.1,dtype=tf.float32),name='W_upscore')\n",
    "\t\tprint_tensor_shape( W_upscore, 'W_upscore shape')\n",
    "#\t\tupscore_conv_op = tf.nn.conv3d_transpose( score_classes_conv_op, W_upscore,output_shape=[BATCH_SIZE,256,256,256,2],strides=[1,16,16,16,1],padding='SAME',name='upscore_conv_op')\n",
    "\t\tupscore_conv_op = tf.nn.conv3d_transpose( score_classes_conv_op, W_upscore,output_shape=[BATCH_SIZE,IMG_DIM,IMG_DIM,IMG_DIM,2],strides=[1,64,64,64,1],padding='SAME',name='upscore_conv_op')\n",
    "#\t\tupscore_conv_op = tf.nn.conv3d_transpose( score_classes_conv_op, W_upscore,output_shape=[1,256,256,256,2],strides=[1,64,64,64,1],padding='SAME',name='upscore_conv_op')\n",
    "\t\tprint_tensor_shape(upscore_conv_op, 'upscore_conv_op shape')\n",
    "\t\n",
    "\treturn upscore_conv_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function to show us tensor shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_tensor_shape(tensor, string):\n",
    "    if __debug__:\n",
    "        print('DEBUG ' + string, tensor.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets load the tfrecord images and push it through our inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DEBUG images shape inference', TensorShape([Dimension(2), Dimension(40), Dimension(40), Dimension(40), Dimension(1)]))\n",
      "('DEBUG W_conv1 shape', TensorShape([Dimension(3), Dimension(3), Dimension(3), Dimension(1), Dimension(10)]))\n",
      "('DEBUG conv1_op shape', TensorShape([Dimension(2), Dimension(20), Dimension(20), Dimension(20), Dimension(10)]))\n",
      "('DEBUG relu1_op shape', TensorShape([Dimension(2), Dimension(20), Dimension(20), Dimension(20), Dimension(10)]))\n",
      "('DEBUG pool1_op shape', TensorShape([Dimension(2), Dimension(10), Dimension(10), Dimension(10), Dimension(10)]))\n",
      "('DEBUG W_conv2 shape', TensorShape([Dimension(3), Dimension(3), Dimension(3), Dimension(10), Dimension(100)]))\n",
      "('DEBUG conv2_op shape', TensorShape([Dimension(2), Dimension(5), Dimension(5), Dimension(5), Dimension(100)]))\n",
      "('DEBUG relu2_op shape', TensorShape([Dimension(2), Dimension(5), Dimension(5), Dimension(5), Dimension(100)]))\n",
      "('DEBUG pool2_op shape', TensorShape([Dimension(2), Dimension(3), Dimension(3), Dimension(3), Dimension(100)]))\n",
      "('DEBUG W_conv3 shape', TensorShape([Dimension(3), Dimension(3), Dimension(3), Dimension(100), Dimension(200)]))\n",
      "('DEBUG conv3_op shape', TensorShape([Dimension(2), Dimension(2), Dimension(2), Dimension(2), Dimension(200)]))\n",
      "('DEBUG relu3_op shape', TensorShape([Dimension(2), Dimension(2), Dimension(2), Dimension(2), Dimension(200)]))\n",
      "('DEBUG W_conv4 shape', TensorShape([Dimension(3), Dimension(3), Dimension(3), Dimension(200), Dimension(200)]))\n",
      "('DEBUG conv4_op shape', TensorShape([Dimension(2), Dimension(1), Dimension(1), Dimension(1), Dimension(200)]))\n",
      "('DEBUG relu4_op shape', TensorShape([Dimension(2), Dimension(1), Dimension(1), Dimension(1), Dimension(200)]))\n",
      "('DEBUG drop_op shape', TensorShape([Dimension(2), Dimension(1), Dimension(1), Dimension(1), Dimension(200)]))\n",
      "('DEBUG W_score_classes_shape', TensorShape([Dimension(1), Dimension(1), Dimension(1), Dimension(200), Dimension(2)]))\n",
      "('DEBUG score_conv_op shape', TensorShape([Dimension(2), Dimension(1), Dimension(1), Dimension(1), Dimension(2)]))\n",
      "('DEBUG W_upscore shape', TensorShape([Dimension(31), Dimension(31), Dimension(31), Dimension(2), Dimension(2)]))\n",
      "('DEBUG upscore_conv_op shape', TensorShape([Dimension(2), Dimension(40), Dimension(40), Dimension(40), Dimension(2)]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Upscore/upscore_conv_op:0' shape=(2, 40, 40, 40, 2) dtype=float32>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainfile = os.path.join(INPUT_DIR,TRAIN_FILE)\n",
    "images, labels = inputs(train=True, batch_size=BATCH_SIZE,num_epochs=NUM_EPOCHS, filename=trainfile)\n",
    "inference(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "\n",
    "This could use some more work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_fn(logits, labels):\t    \n",
    "\t# input:  logits: Logits tensor, float - [batch_size, 256, 256, 256, 2].\n",
    "\t# intput: labels: Labels tensor, int8 - [batch_size, 256, 256, 256].\n",
    "\t# output: loss: Loss tensor of type float.\n",
    "\t\n",
    "\tlabels = tf.to_int64(labels)\n",
    "\tprint_tensor_shape( logits, 'logits shape ')\n",
    "\tprint_tensor_shape( labels, 'labels shape ')\n",
    "\t\n",
    "\t# reshape to match args required for the cross entropy function\n",
    "\tlogits_re = tf.reshape( logits, [-1, 2] )\n",
    "\tlabels_re = tf.reshape( labels, [-1] )\n",
    "\t#print_tensor_shape( logits_re, 'logits shape after')\n",
    "\t#print_tensor_shape( labels_re, 'labels shape after')\n",
    "\t\n",
    "\t# call cross entropy with logits\n",
    "\tcross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels, name='cross_entropy')\n",
    "\tprint_tensor_shape( cross_entropy, 'cross_entropy shape ')\n",
    "\t\n",
    "\tloss = tf.reduce_mean(cross_entropy, name='1cnn_cross_entropy_mean')\n",
    "\tprint_tensor_shape( loss, 'loss shape ')\n",
    "\t\n",
    "\treturn loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
